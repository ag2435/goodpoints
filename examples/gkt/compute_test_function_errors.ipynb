{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for evaluating various test function errors ONLY AFTER the coresets are already generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import numpy.linalg as npl\n",
    "from scipy.spatial.distance import pdist\n",
    "\n",
    "from argparse import ArgumentParser\n",
    "import pickle as pkl\n",
    "import pathlib\n",
    "import os\n",
    "import os.path\n",
    "\n",
    "# import kernel thinning\n",
    "from goodpoints import kt # kt.thin is the main thinning function; kt.split and kt.swap are other important functions\n",
    "from goodpoints.util import isnotebook # Check whether this file is being executed as a script or as a notebook\n",
    "from goodpoints.util import fprint  # for printing while flushing buffer\n",
    "from goodpoints.tictoc import tic, toc # for timing blocks of code\n",
    "\n",
    "\n",
    "# utils for generating samples, evaluating kernels, and mmds\n",
    "from util_sample import sample, compute_mcmc_params_p, compute_diag_mog_params, sample_string, compute_params_p\n",
    "from util_k_mmd import kernel_eval, p_kernel, ppn_kernel, pp_kernel, pnpn_kernel, squared_mmd, get_combined_results_filename, compute_params_k\n",
    "from util_parse import init_parser, convert_arg_flags\n",
    "\n",
    "# for partial functions, to use kernel_eval for kernel\n",
    "from functools import partial\n",
    "\n",
    "# set things a bit when running the notebook\n",
    "if isnotebook():\n",
    "    # Autoreload packages that are modified\n",
    "    %load_ext autoreload\n",
    "    %autoreload 2\n",
    "    %matplotlib inline\n",
    "    %load_ext line_profiler\n",
    "    # https://jakevdp.github.io/PythonDataScienceHandbook/01.07-timing-and-profiling.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Function for loading input and coresets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_input_and_coreset(m, params_p, params_k_split, params_k_swap, rep_id, thin_str=\"\", delta=0.5, \n",
    "                      sample_seed=1234567, thin_seed=9876543, results_dir=\"results_new\", verbose=False):\n",
    "    \"\"\"Return exisiting KT coresets by loading from disk, and the associated MC points used for finding the coresets\n",
    "   along with ST coresets\n",
    "   Gives error if the coreset does not exist\n",
    "    Args:\n",
    "      m: Number of halving rounds (number of sample points n = 2^{2m})\n",
    "      params_p: Dictionary of distribution parameters recognized by sample()\n",
    "      params_k_split: Dictionary of kernel parameters recognized by kernel() # used for kt split\n",
    "      params_k_swap: Dictionary of kernel parameters recognized by kernel() # used for kt swap; and computing mmd\n",
    "      rep_id: A single rep id for which coreset to be returned\n",
    "      thin_str: (Optional), str to be appended to filenames when loading coresets other than KT and iid/ST, e.g., kt.split + rand\n",
    "      delta: If c is None, delta/(4^m) is the failure probability for\n",
    "        adaptive threshold sequence\n",
    "      sample_seed: (Optional) random seed is set to sample_seed + rep\n",
    "        prior to generating input sample for replication rep\n",
    "      thin_seed: (Optional) random seed is set to thin_seed + rep\n",
    "        prior to running thinning for replication rep\n",
    "      results_dir: (Optional) Directory in which results is to be loaded from\n",
    "      verbose: (Optional) If True, print intermediate updates\n",
    "    \"\"\"\n",
    "    \n",
    "    d = params_p[\"d\"]\n",
    "    assert(d == params_k_split[\"d\"])\n",
    "    assert(d == params_k_swap[\"d\"])\n",
    "    sample_str = sample_string(params_p, sample_seed)\n",
    "    split_kernel_str = \"{}_var{:.3f}_seed{}\".format(params_k_split[\"name\"], params_k_split[\"var\"], thin_seed)\n",
    "    swap_kernel_str =  \"{}_var{:.3f}\".format(params_k_swap[\"name\"], params_k_swap[\"var\"])\n",
    "    thresh_str = f\"delta{delta}\"\n",
    "    file_template = os.path.join(results_dir, f\"kt{thin_str}-coresets-{sample_str}-split{split_kernel_str}-swap{swap_kernel_str}-d{d}-m{m}-{thresh_str}-rep{{}}.pkl\")\n",
    "    \n",
    "    filename = file_template.format(rep_id)\n",
    "    n = int(2**(2*m))\n",
    "    ncoreset = int(2**m)\n",
    "    X = sample(n, params_p, seed=sample_seed+rep_id)\n",
    "    if os.path.exists(filename):\n",
    "        with open(filename, 'rb') as file:\n",
    "            if verbose:\n",
    "                print(f\"Loading KT coreset indices from {filename}\")\n",
    "            coresets = pkl.load(file)\n",
    "    else:\n",
    "        raise ValueError(f\"File {filename} not found\")\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Returning all {n} input MC points and {ncoreset} KT points\")\n",
    "        \n",
    "    return(X, coresets[:ncoreset])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Function for evaluating integration errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_fun_approx_quality(fun_str, ms, params_p, params_k_split, params_k_swap, rep_ids,\n",
    "        thin_str=\"\",  delta=0.5,  sample_seed=1234567, thin_seed=9876543,\n",
    "        compute_fun_diff = True, rerun=False, results_dir=\"results_new\", return_val=False):\n",
    "    \"\"\"Returns |Pinf-Pout f|, |Pf - Poutf| for KT/KTrt/KT+ and ST\n",
    "    \n",
    "    Args:\n",
    "    fun_str: the test function to be evaluated must be in the list\n",
    "             {k0, x, x^2, pk, kmean, x1x2, cov, l1_x, linf_x, cif, gfun, cos, cosg, kernel}\n",
    "             - some functions might have constraints on what settings allowed\n",
    "             - add another function by adding an \"if block\" in this code\n",
    "      ms: range of output coreset sizes (2^m for m in ms)\n",
    "      params_p: Dictionary of distribution parameters recognized by sample()\n",
    "      params_k_split: Dictionary of kernel parameters recognized by kernel_eval()\n",
    "      params_k_swap: Dictionary of kernel parameters recognized by kernel_eval()\n",
    "      rep_ids: Which replication numbers of experiment to run; the replication\n",
    "        number determines the seeds set for reproducibility\n",
    "      thin_str: (Optional), str to be appended to filenames when loading coresets other than KT/KT power and iid/ST, e.g., \"-plus\" for KT+\n",
    "      delta: delta/(4^m) is the failure probability for\n",
    "        adaptive threshold sequence;\n",
    "      sample_seed: (Optional) random seed is set to sample_seed + rep\n",
    "        prior to generating input sample for replication rep\n",
    "      thin_seed: (Optional) random seed is set to thin_seed + rep\n",
    "        prior to running thinning for replication rep\n",
    "      compute_fun_diff: (Optional)\n",
    "      rerun: (Optional) If False and results have been previously saved to\n",
    "        disk, load results from disk instead of recomputing the errors\n",
    "      results_dir: (Optional) Directory in which results should be saved\n",
    "      return_val:(Optional) Whether to return the |Pinf-Pout f|, |Pf - Poutf| for KT, and ST (4 quantities in total) OR not\n",
    "    \"\"\"\n",
    "    # Create results directory if necessary\n",
    "    pathlib.Path(results_dir).mkdir(parents=True, exist_ok=True)\n",
    "    d = params_p[\"d\"]\n",
    "    assert(d==params_k_split[\"d\"])\n",
    "    assert(d==params_k_swap[\"d\"])\n",
    "    \n",
    "    # create split and swap kernel functions from the parameters\n",
    "    split_kernel = partial(kernel_eval, params_k=params_k_split)\n",
    "    swap_kernel = partial(kernel_eval, params_k=params_k_swap)\n",
    "    \n",
    "    # Construct results filename template with placeholder for rep value\n",
    "    sample_str = sample_string(params_p, sample_seed)\n",
    "    split_kernel_str = \"{}_var{:.3f}_seed{}\".format(params_k_split[\"name\"], params_k_split[\"var\"], thin_seed)\n",
    "    swap_kernel_str =  \"{}_var{:.3f}\".format(params_k_swap[\"name\"], params_k_swap[\"var\"])\n",
    "    thresh_str = f\"delta{delta}\"\n",
    "    \n",
    "    orig_fun_str = fun_str # for easeness, as we change fun_str to use previous results\n",
    "    if fun_str == 'k0': fun_str = \"\" # changed to remain consistent with previous computations\n",
    "\n",
    "    ########### DEFINE FUNCTIONS AND COMPUTE Pf WHENEVER COMPUTABLE ##########\n",
    "    # If Pf is not available, then we later set Pf = Pinf (which is always COMPUTABLE)\n",
    "    \n",
    "    if fun_str == \"\": # f(x) = k(0, x)\n",
    "        yloc = np.zeros((1, d))\n",
    "        fun = partial(swap_kernel, y=yloc)\n",
    "        p_fun = p_kernel(yloc, params_k=params_k_swap, params_p=params_p)[0] # fun is fixed to be k(yloc, .)\n",
    "        \n",
    "    if fun_str == 'pk':\n",
    "        fun = partial(p_kernel, params_k=params_k_swap, params_p=params_p)\n",
    "        p_fun = pp_kernel(params_k_swap, params_p)\n",
    "        \n",
    "    if fun_str == 'kmean': # f(x)=Pk(x), enabled only for MCMC experiments where P is fixed to Phat/Pnmax\n",
    "        assert(\"Pnmax\" in params_p)\n",
    "        yloc = params_p[\"Pnmax\"].mean(0).reshape(1, -1) # mean over samples\n",
    "        fun = partial(swap_kernel, y=yloc)\n",
    "        p_fun = p_kernel(yloc, params_k=params_k_swap, params_p=params_p)[0] # fun is fixed to be k(yloc, .)\n",
    "    \n",
    "    if fun_str == 'x': # first coordinate\n",
    "        def fun(x): return(x[:,0])\n",
    "        if params_p[\"name\"] == \"gauss\":\n",
    "            p_fun = 0.\n",
    "        if \"Pnmax\" in params_p:\n",
    "            p_fun = np.mean(fun(params_p[\"Pnmax\"]))\n",
    "        if params_p[\"name\"] == \"diag_mog\" and (len(params_p[\"weights\"])==4 or len(params_p[\"weights\"])==8):\n",
    "            p_fun = 0.\n",
    "            \n",
    "    if fun_str == 'x1x2': # product of first two coordinates\n",
    "        def fun(x): return(x[:,0]*x[:,1])\n",
    "        if params_p[\"name\"] == \"gauss\":\n",
    "            p_fun = 0.\n",
    "        if \"Pnmax\" in params_p:\n",
    "            p_fun = np.mean(fun(params_p[\"Pnmax\"]))\n",
    "        if params_p[\"name\"] == \"diag_mog\" and (len(params_p[\"weights\"])==4 or len(params_p[\"weights\"])==8):\n",
    "            p_fun = 0.\n",
    "            \n",
    "    if fun_str == 'cov': # Covariance function E[(X-mu)(X-mu)^T]\n",
    "        assert(params_p[\"name\"]==\"gauss\")\n",
    "        def fun(X): return(X.T.dot(X)/X.shape[0]-np.outer(X.mean(0),X.mean(0)))\n",
    "        if params_p[\"name\"] == \"gauss\":\n",
    "            p_fun = params_p[\"var\"]*np.eye(d)\n",
    "    \n",
    "    if fun_str == 'l1_x' or fun_str == 'linf_x': # want to compute |P X-Pout X|_1 and |P X-Pout X|_inf, so here we compute PX\n",
    "        def fun(x): return(x)\n",
    "        if params_p[\"name\"] == \"gauss\":\n",
    "            p_fun = np.zeros(d)\n",
    "        if \"Pnmax\" in params_p:\n",
    "            p_fun = np.mean(fun(params_p[\"Pnmax\"]), 0)\n",
    "        if params_p[\"name\"] == \"diag_mog\" and (len(params_p[\"weights\"])==4 or len(params_p[\"weights\"])==8):\n",
    "            p_fun = np.zeros(d)\n",
    "     \n",
    "    if fun_str == 'x^2': # first coordinate squared\n",
    "        def fun(x): return(x[:, 0]**2)\n",
    "        if params_p[\"name\"] == \"gauss\":\n",
    "            p_fun = params_p[\"var\"]\n",
    "        if \"Pnmax\" in params_p:\n",
    "            p_fun = np.mean(fun(params_p[\"Pnmax\"]), 0)\n",
    "        if params_p[\"name\"] == \"diag_mog\" and (len(params_p[\"weights\"])==4 or len(params_p[\"weights\"])==8):\n",
    "            p_fun = params_p[\"mean_sqdist\"]/4.\n",
    "        \n",
    "    # for these functions Pf is not directly available; and we only compute Pinf (And set Pf = Pinf)\n",
    "    if fun_str == 'cif':  # https://www.sfu.ca/~ssurjano/cont.html\n",
    "        def fun(x): \n",
    "            # function from here\n",
    "            d = x.shape[1]\n",
    "            u = npr.default_rng(0).uniform(size=(1, d))\n",
    "            a = 1. / d * np.ones(d)\n",
    "            return(np.exp(np.sum(-np.abs(x-u.reshape(1, -1)) * a, axis=1 ) ))\n",
    "        \n",
    "    if fun_str == \"gfun\": # https://www.sfu.ca/~ssurjano/gfunc.html\n",
    "        def fun(x):\n",
    "            # function from here\n",
    "            d = x.shape[1]\n",
    "            a = 0.5*np.arange(1, d+1)  - 1\n",
    "            return(np.prod((np.abs(4*x - 2) + a.reshape(1, -1) ) / (1+a), axis=1))\n",
    "    \n",
    "    if fun_str == \"cos\": # cosine function; https://www.sfu.ca/~ssurjano/oscil.html\n",
    "        def fun(x):\n",
    "            d = x.shape[1] \n",
    "            u = npr.default_rng(0).uniform()\n",
    "            return(np.cos(2*np.pi*u+ 5./d * np.sum(x , axis=1 ) ))\n",
    "    \n",
    "    if fun_str == \"cosg\": # cosine * gaussian function; p\n",
    "        def fun(x):\n",
    "            d = x.shape[1] \n",
    "            u = npr.default_rng(0).uniform()\n",
    "            return(np.exp(-5./d*np.sum(x**2, axis=1)) * np.cos(2*np.pi*u+ 5./d * np.sum(x , axis=1 ) ))\n",
    "        \n",
    "    if fun_str == \"kernel\": # f(x) = k(X', x) for X' ~ P\n",
    "        if params_p[\"name\"]  != \"gauss\" and \"mog\" not in params_p[\"name\"]:\n",
    "            u = npr.default_rng(100).choice(len(params_p[\"Pnmax\"]))\n",
    "            u = 2 * params_p[\"Pnmax\"][u] - np.mean(params_p[\"Pnmax\"], 0)\n",
    "        else:\n",
    "            # generate a randomvariable\n",
    "            u = sample(1, params_p,  npr.default_rng(0)) # 2 * np.sqrt(params_p[\"var\"]) * npr.default_rng(0).standard_normal(size=(1, params_p[\"d\"]))\n",
    "        def fun(x):\n",
    "            d = x.shape[1] \n",
    "            return(kernel_eval(x, u, params_k=params_k_swap))\n",
    "        if params_p[\"name\"] == \"gauss\" and params_k[\"name\"] == \"gauss\":\n",
    "            p_fun = p_kernel(y=u, params_k=params_k_swap, params_p=params_p)            \n",
    "       \n",
    "    ########### COMPUTE Pinf and Poutf  ##########\n",
    "    \n",
    "    # initialize matrices of entries       \n",
    "    fun_diff_p = np.zeros((len(ms), len(rep_ids))) # for Pf - Pout f\n",
    "    fun_diff_p_sin = np.zeros((len(ms), len(rep_ids))) # Pinf - Pout f\n",
    "    fun_diff_p_st = np.zeros((len(ms), len(rep_ids))) #  Pf - Pout f for standard thinning\n",
    "    fun_diff_p_sin_st = np.zeros((len(ms), len(rep_ids))) # Pinf - Pout f for standard thinning\n",
    "    \n",
    "    fprint(f\"Evaluating coresets for function {orig_fun_str} for setting \\\n",
    "           {get_combined_results_filename('', ms, params_p, params_k_split=params_k_split, params_k_swap=params_k_swap, rep_ids=rep_ids, delta=delta)}.....\")\n",
    "    generic_prefixes = [f\"-combinedfundiff{fun_str}-\", f\"-sin-combinedfundiff{fun_str}-\"]\n",
    "    \n",
    "    compute_st = False\n",
    "    compute_kt = False\n",
    "    # check if things are already stored then don't compute the respective items\n",
    "    if not rerun:\n",
    "        prefixes = [\"mc\" + prefix for prefix in generic_prefixes]\n",
    "        for prefix in prefixes:\n",
    "            filename = get_combined_results_filename(prefix, ms, params_p, params_k_split=params_k_split, params_k_swap=params_k_swap, rep_ids=rep_ids, delta=delta)\n",
    "            if not os.path.exists(filename):\n",
    "                compute_st = True\n",
    "\n",
    "        prefixes = [f\"kt{thin_str}\" + prefix for prefix in generic_prefixes]\n",
    "        for prefix in prefixes:\n",
    "            filename = get_combined_results_filename(prefix, ms, params_p, params_k_split=params_k_split, params_k_swap=params_k_swap, rep_ids=rep_ids, delta=delta)\n",
    "            if not os.path.exists(filename):\n",
    "                compute_kt = True\n",
    "    else:\n",
    "        compute_st = True\n",
    "        compute_kt = True\n",
    "    \n",
    "    if compute_st or compute_kt:\n",
    "        for m in ms:\n",
    "            # print(m)\n",
    "            for r_i, rep in enumerate(rep_ids):\n",
    "                # load coresets\n",
    "                Xin, kt_coresets = load_input_and_coreset(m, params_p, params_k_split, params_k_swap, rep_id=rep, thin_str=thin_str, delta=delta, \n",
    "                              sample_seed=sample_seed, thin_seed=thin_seed, results_dir=results_dir, verbose=False)\n",
    "                \n",
    "                # compute Pinf for various functions\n",
    "                if fun_str == 'cov':\n",
    "                    pin_fun = fun(Xin)\n",
    "                elif fun_str not in ['cif', 'gfun', 'cos' ,'cosg', 'kernel']:\n",
    "                    pin_fun = np.mean(fun(Xin), 0) if not params_p[\"saved_samples\"] else p_fun # to save time, ignore pk setting with pin for mcmc cases\n",
    "                else:\n",
    "                    pin_fun = np.mean(fun(Xin), 0)\n",
    "                    \n",
    "                if 'p_fun' not in locals(): p_fun = pin_fun\n",
    "                \n",
    "                # compute Pout f for KT\n",
    "                if compute_kt:\n",
    "                    if fun_str == 'cov':\n",
    "                        pout_fun_kt = fun(Xin[kt_coresets])\n",
    "                    else:\n",
    "                        pout_fun_kt = np.mean(fun(Xin[kt_coresets]), 0)\n",
    "                   \n",
    "                    if fun_str == 'l1_x' or fun_str == 'cov':\n",
    "                        multiply_factor = 1. if fun_str == 'l1_x' else 1./d**2 # normalize by d^2 for covariance\n",
    "                        fun_diff_p[m, r_i] = multiply_factor * np.sum(np.abs(p_fun-pout_fun_kt))\n",
    "                        fun_diff_p_sin[m, r_i] =  multiply_factor * np.sum(np.abs(pin_fun-pout_fun_kt))\n",
    "                    elif fun_str == 'linf_x':\n",
    "                        fun_diff_p[m, r_i] = max(np.abs(p_fun-pout_fun_kt))\n",
    "                        fun_diff_p_sin[m, r_i] = max(np.abs(pin_fun-pout_fun_kt))\n",
    "                    else:\n",
    "                        fun_diff_p[m, r_i] = np.abs(p_fun-pout_fun_kt)\n",
    "                        fun_diff_p_sin[m, r_i] = np.abs(pin_fun-pout_fun_kt)\n",
    "                   \n",
    "                # compute Poutf for ST\n",
    "                if compute_st:\n",
    "                    step = int(2**m)\n",
    "                    if fun_str == 'cov':\n",
    "                        pout_fun_st = fun(Xin[step-1:int(2**(2*m)):step])\n",
    "                    else:\n",
    "                        pout_fun_st = np.mean(fun(Xin[step-1:int(2**(2*m)):step]))\n",
    "                        \n",
    "                    if fun_str == 'l1_x' or fun_str == 'cov':\n",
    "                        multiply_factor = 1. if fun_str == 'l1_x' else 1./d**2\n",
    "                        fun_diff_p_st[m, r_i] =  multiply_factor * np.sum(np.abs(p_fun-pout_fun_st))\n",
    "                        fun_diff_p_sin_st[m, r_i] = multiply_factor * np.sum(np.abs(pin_fun-pout_fun_st))\n",
    "                    elif fun_str == 'linf_x':\n",
    "                        fun_diff_p_st[m, r_i] = max(np.abs(p_fun-pout_fun_st))\n",
    "                        fun_diff_p_sin_st[m, r_i] = max(np.abs(pin_fun-pout_fun_st))\n",
    "                    else:\n",
    "                        fun_diff_p_st[m, r_i] = np.abs(p_fun-pout_fun_st)\n",
    "                        fun_diff_p_sin_st[m, r_i] = np.abs(pin_fun-pout_fun_st)\n",
    "    \n",
    "    ########### SAVE RESULTS ########## \n",
    "    # stanfard thinning results are saved with \"mc prefix\" \n",
    "    prefixes = [\"mc\" + prefix for prefix in generic_prefixes]\n",
    "    if compute_st:      \n",
    "        for prefix, data_array in zip(prefixes, [fun_diff_p_st, fun_diff_p_sin_st]):\n",
    "            filename = get_combined_results_filename(prefix, ms, params_p, params_k_split=params_k_split, params_k_swap=params_k_swap, rep_ids=rep_ids, delta=delta)\n",
    "            with open(filename, 'wb') as file:\n",
    "                print(f\"Saving {prefix} to {filename}\")\n",
    "                pkl.dump(data_array, file, protocol=pkl.HIGHEST_PROTOCOL)\n",
    "    else:\n",
    "        if return_val:\n",
    "            prefix = prefixes[0]\n",
    "            filename = get_combined_results_filename(prefix, ms, params_p, params_k_split=params_k_split, params_k_swap=params_k_swap, rep_ids=rep_ids, delta=delta)\n",
    "            with open(filename, 'rb') as file:\n",
    "                print(f\"Loading {prefix} from {filename}\")\n",
    "                fun_diff_p_st = pkl.load(file)\n",
    "\n",
    "            prefix = prefixes[1]\n",
    "            filename = get_combined_results_filename(prefix, ms, params_p, params_k_split=params_k_split, params_k_swap=params_k_swap, rep_ids=rep_ids, delta=delta)\n",
    "            with open(filename, 'rb') as file:\n",
    "                print(f\"Loading {prefix} from {filename}\")\n",
    "                fun_diff_p_sin_st = pkl.load(file)\n",
    "\n",
    "    prefixes = [f\"kt{thin_str}\" + prefix for prefix in generic_prefixes]      \n",
    "    if compute_kt:\n",
    "        for prefix, data_array in zip(prefixes, [fun_diff_p, fun_diff_p_sin]):\n",
    "            filename = get_combined_results_filename(prefix, ms, params_p, params_k_split=params_k_split, params_k_swap=params_k_swap, rep_ids=rep_ids, delta=delta)\n",
    "            with open(filename, 'wb') as file:\n",
    "                print(f\"Saving {prefix} to {filename}\")\n",
    "                pkl.dump(data_array, file, protocol=pkl.HIGHEST_PROTOCOL)\n",
    "    else:\n",
    "        if return_val:\n",
    "            prefix = prefixes[0]\n",
    "            filename = get_combined_results_filename(prefix, ms, params_p, params_k_split=params_k_split, params_k_swap=params_k_swap, rep_ids=rep_ids, delta=delta)\n",
    "            with open(filename, 'rb') as file:\n",
    "                print(f\"Loading {prefix} from {filename}\")\n",
    "                fun_diff_p = pkl.load(file)\n",
    "\n",
    "            prefix = prefixes[1]\n",
    "            filename = get_combined_results_filename(prefix, ms, params_p, params_k_split=params_k_split, params_k_swap=params_k_swap, rep_ids=rep_ids, delta=delta)\n",
    "            with open(filename, 'rb') as file:\n",
    "                print(f\"Loading {prefix} from {filename}\")\n",
    "                fun_diff_p_sin = pkl.load(file)\n",
    "            \n",
    "    if return_val:\n",
    "        return(fun_diff_p, fun_diff_p_sin, fun_diff_p_st, fun_diff_p_sin_st)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize argumennts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if isnotebook():\n",
    "parser = init_parser()\n",
    "args, opt = parser.parse_known_args()\n",
    "args = convert_arg_flags(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gauss Experiments Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rerun = True # whether to rerun the integratione rror computations\n",
    "args.d = 2 # d\n",
    "args.kernel = \"gauss\" # kernel\n",
    "args.P = \"gauss\" # target P setting; allowed values depend on the feasible arguments in compute_params_p; currently {gauss, mog, mcmc} \n",
    "args.computepower = True # whether to compute results for power KT (same as root KT when power = 0.5)\n",
    "args.power = 0.5 # power of the kernel to be used for power KT and KT+\n",
    "args.ktplus = False # whether to run results for KT+\n",
    "args.targetkt = True # whether to run results for KT+\n",
    "args.powerkt = True # whether to run results for KT+\n",
    "fun_strs = ['kernel', 'x', 'cif'] # which functions to evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for gauss P the only free parameter is dimension d; everything else is computed in compute_params_p/compute_params_k\n",
    "ds = [2, 10, 20, 50, 100] \n",
    "for d in ds:\n",
    "    args.d = d\n",
    "    d, params_p, var_k =  compute_params_p(args)\n",
    "    params_k, params_k_power = compute_params_k(args, var_k, args.computepower, args.power)\n",
    "    \n",
    "    if args.ktplus: # if running KT+, need to define the KT+ kernel called as params_k_combo\n",
    "        assert(args.power is not None)\n",
    "        params_k_combo = dict()\n",
    "        params_k_combo[\"name\"] = \"combo_\"  + params_k[\"name\"] + f\"_{args.power}\"\n",
    "        params_k_combo[\"k\"] = params_k.copy()\n",
    "        params_k_combo[\"kpower\"] = params_k_power.copy()\n",
    "        params_k_combo[\"var\"] = params_k[\"var\"]\n",
    "        params_k_combo[\"d\"] = args.d\n",
    "        \n",
    "    \n",
    "    params_k_split_list = []\n",
    "    thin_str_list = []\n",
    "    if args.targetkt:\n",
    "        params_k_split_list.append(params_k)\n",
    "        thin_str_list.append(\"\")\n",
    "    if args.powerkt:\n",
    "        params_k_split_list.append(params_k_power)\n",
    "        thin_str_list.append(\"\")\n",
    "    if args.ktplus:\n",
    "        params_k_split_list.append(params_k_combo)\n",
    "        thin_str_list.append(\"-plus\")\n",
    "\n",
    "    for fun_str in fun_strs:\n",
    "        for params_k_split, thin_str in zip(params_k_split_list, thin_str_list):\n",
    "            fun_diff_p, fun_diff_p_sin, fun_diff_p_st, fun_diff_p_sin_st = evaluate_fun_approx_quality(fun_str=fun_str,\n",
    "                ms=range(7+1), params_p=params_p, params_k_split=params_k_split, params_k_swap=params_k, rep_ids=range(10),\n",
    "                                            thin_str=thin_str, \n",
    "                             delta=0.5,\n",
    "                              sample_seed=1234567, thin_seed=9876543,\n",
    "                              rerun=rerun, results_dir=\"results_new\",return_val = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MCMC results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mcmc_filenames = np.array(['Hinch_P_seed_1_temp_1_scaled', 'Hinch_P_seed_2_temp_1_scaled', \n",
    "                               'Hinch_TP_seed_1_temp_8_scaled', 'Hinch_TP_seed_2_temp_8_scaled', \n",
    "                                'Goodwin_RW_float_step', 'Goodwin_ADA-RW_float_step', \n",
    "                               'Goodwin_MALA_float_step',  'Goodwin_PRECOND-MALA_float_step',  \n",
    "                               'Lotka_RW_float_step',  'Lotka_ADA-RW_float_step', \n",
    "                               'Lotka_MALA_float_step', 'Lotka_PRECOND-MALA_float_step'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lotka and Goodwin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rerun = True\n",
    "args.d = int(4)\n",
    "args.kernel, args.power = \"laplace\", 0.81 # we used different power for different kernels\n",
    "# args.kernel, args.power = \"imq\", 0.5\n",
    "# args.kernel, args.power = \"gauss\", 0.5\n",
    "args.P = \"mcmc\" # target P setting; allowed values depend on the feasible arguments in compute_params_p; currently {gauss, mog, mcmc} \n",
    "args.computepower = True  # whether to compute results for power KT (same as root KT when power = 0.5)\n",
    "args.ktplus = True # whether to run results for KT+\n",
    "args.targetkt = False # whether to run results for Target KT\n",
    "args.powerkt = False # whether to run results for power KT\n",
    "file_idx = range(4, 12) # since this code block runs only for Goodwin and Lotka to run results for KT+\n",
    "fun_strs = ['kernel', 'x', 'x^2', 'cif'] #, 'x', 'x^2', 'cif']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for filename in all_mcmc_filenames[file_idx]:\n",
    "    args.filename = filename\n",
    "    d, params_p, var_k =  compute_params_p(args)\n",
    "    args.d = d\n",
    "    params_k, params_k_power = compute_params_k(args, var_k, args.computepower, args.power)\n",
    "    \n",
    "    if args.ktplus:\n",
    "        assert(args.power is not None)\n",
    "        params_k_combo = dict()\n",
    "        params_k_combo[\"name\"] = \"combo_\"  + params_k[\"name\"] + f\"_{args.power}\"\n",
    "        params_k_combo[\"k\"] = params_k.copy()\n",
    "        params_k_combo[\"kpower\"] = params_k_power.copy()\n",
    "        params_k_combo[\"var\"] = params_k[\"var\"]\n",
    "        params_k_combo[\"d\"] = args.d\n",
    "    \n",
    "    params_k_split_list = []\n",
    "    thin_str_list = []\n",
    "    if args.targetkt:\n",
    "        params_k_split_list.append(params_k)\n",
    "        thin_str_list.append(\"\")\n",
    "    if args.powerkt:\n",
    "        params_k_split_list.append(params_k_power)\n",
    "        thin_str_list.append(\"\")\n",
    "    if args.ktplus:\n",
    "        params_k_split_list.append(params_k_combo)\n",
    "        thin_str_list.append(\"-plus\")\n",
    "\n",
    "    for fun_str in fun_strs:\n",
    "        for params_k_split, thin_str in zip(params_k_split_list, thin_str_list):\n",
    "            evaluate_fun_approx_quality(fun_str=fun_str,\n",
    "                ms=range(7+1), params_p=params_p, params_k_split=params_k_split, params_k_swap=params_k, rep_ids=range(10),\n",
    "                                            thin_str=thin_str, \n",
    "                             delta=0.5,\n",
    "                              sample_seed=1234567, thin_seed=9876543,\n",
    "                              rerun=rerun, results_dir=\"results_new\",return_val = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hinch experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rerun = True\n",
    "args.d = int(38)\n",
    "args.kernel, args.power = \"imq\", 0.5\n",
    "args.P = \"mcmc\"  # target P setting; allowed values depend on the feasible arguments in compute_params_p; currently {gauss, mog, mcmc} \n",
    "args.computepower = True\n",
    "args.ktplus = True # whether to run results for KT+\n",
    "args.targetkt = False # whether to run results for Target KT\n",
    "args.powerkt = False # whether to run results for power KT\n",
    "file_idx = range(4) # since this code block runs only for Hinch\n",
    "fun_strs = ['kernel', 'x', 'x^2', 'cif'] #, 'x', 'x^2', 'cif']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in all_mcmc_filenames[file_idx]:\n",
    "    args.filename = filename\n",
    "    d, params_p, var_k =  compute_params_p(args)\n",
    "    args.d = d\n",
    "    params_k, params_k_power = compute_params_k(args, var_k, args.computepower, args.power)\n",
    "    \n",
    "    if args.ktplus:\n",
    "        assert(args.power is not None)\n",
    "        params_k_combo = dict()\n",
    "        params_k_combo[\"name\"] = \"combo_\"  + params_k[\"name\"] + f\"_{args.power}\"\n",
    "        params_k_combo[\"k\"] = params_k.copy()\n",
    "        params_k_combo[\"kpower\"] = params_k_power.copy()\n",
    "        params_k_combo[\"var\"] = params_k[\"var\"]\n",
    "        params_k_combo[\"d\"] = args.d\n",
    "\n",
    "    params_k_split_list = []\n",
    "    thin_str_list = []\n",
    "    if args.targetkt:\n",
    "        params_k_split_list.append(params_k)\n",
    "        thin_str_list.append(\"\")\n",
    "    if args.powerkt:\n",
    "        params_k_split_list.append(params_k_power)\n",
    "        thin_str_list.append(\"\")\n",
    "    if args.ktplus:\n",
    "        params_k_split_list.append(params_k_combo)\n",
    "        thin_str_list.append(\"-plus\")\n",
    "\n",
    "    for fun_str in fun_strs:\n",
    "        for params_k_split, thin_str in zip(params_k_split_list, thin_str_list):\n",
    "            evaluate_fun_approx_quality(fun_str=fun_str,\n",
    "                ms=range(7+1), params_p=params_p, params_k_split=params_k_split, params_k_swap=params_k, rep_ids=range(10),\n",
    "                                            thin_str=thin_str, \n",
    "                             delta=0.5,\n",
    "                              sample_seed=1234567, thin_seed=9876543,\n",
    "                              rerun=rerun, results_dir=\"results_new\",return_val = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MOG results with 4 and 8 components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rerun = False # whether to rerun the integratione rror computations\n",
    "args.d = 2 # d\n",
    "args.kernel = \"gauss\" # kernel\n",
    "args.P = \"mog\" # target P setting; allowed values depend on the feasible arguments in compute_params_p; currently {gauss, mog, mcmc} \n",
    "args.computepower = True # whether to compute results for power KT (same as root KT when power = 0.5)\n",
    "args.power = 0.5 # power of the kernel to be used for power KT and KT+\n",
    "args.ktplus = True # whether to run results for KT+\n",
    "fun_strs = ['kernel'] # which functions to evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for mog P the only free parameter is number of components M; everything else is computed in compute_params_p/compute_params_k\n",
    "Ms = [4, 8] \n",
    "for M in Ms:\n",
    "    args.M = M\n",
    "    d, params_p, var_k =  compute_params_p(args)\n",
    "    params_k, params_k_power = compute_params_k(args, var_k, args.computepower, args.power)\n",
    "    \n",
    "    if args.ktplus: # if running KT+, need to define the KT+ kernel called as params_k_combo\n",
    "        assert(args.power is not None)\n",
    "        params_k_combo = dict()\n",
    "        params_k_combo[\"name\"] = \"combo_\"  + params_k[\"name\"] + f\"_{args.power}\"\n",
    "        params_k_combo[\"k\"] = params_k.copy()\n",
    "        params_k_combo[\"kpower\"] = params_k_power.copy()\n",
    "        params_k_combo[\"var\"] = params_k[\"var\"]\n",
    "        params_k_combo[\"d\"] = args.d\n",
    "        \n",
    "    for fun_str in fun_strs: # compute results for each function; \n",
    "        # if args.ktplus is trye then results for KT/powerKT/KT+ are all computed, else only for KT\n",
    "        # in either case, results for ST are returned\n",
    "        for params_k_split, thin_str in zip([params_k, params_k_power, params_k_combo], [\"\", \"\", \"-plus\"]) if args.ktplus else zip([params_k], [\"\"]):\n",
    "            fun_diff_p, fun_diff_p_sin, fun_diff_p_st, fun_diff_p_sin_st = evaluate_fun_approx_quality(fun_str=fun_str,\n",
    "                ms=range(7+1), params_p=params_p, params_k_split=params_k_split, params_k_swap=params_k, rep_ids=range(10),\n",
    "                                            thin_str=thin_str, \n",
    "                             delta=0.5,\n",
    "                              sample_seed=1234567, thin_seed=9876543,\n",
    "                              rerun=rerun, results_dir=\"results_new\",return_val = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
