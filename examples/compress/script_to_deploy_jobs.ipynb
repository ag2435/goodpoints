{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ea6579e-cad8-40aa-9f04-388abf9023a8",
   "metadata": {},
   "source": [
    "# Notebook that runs thinning experiments as separate jobs locally or on Slurm cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e1e960-caf6-463f-a38d-5aa57f279c1d",
   "metadata": {},
   "source": [
    "## 1. Specify whether jobs will be run on Slurm cluster or locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeba2a07-b66e-4633-aae8-23ca88a5a29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "deploy_slurm = True\n",
    "\n",
    "import subprocess # to use subprocess \n",
    "import pathlib\n",
    "import os\n",
    "import os.path\n",
    "import pickle as pkl\n",
    "from datetime import datetime\n",
    "if deploy_slurm:\n",
    "    from slurmpy import Slurm\n",
    "import numpy as np\n",
    "from goodpoints.util import isnotebook # Check whether this file is being executed as a script or as a notebook\n",
    "if isnotebook():\n",
    "    %load_ext autoreload\n",
    "    %autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1e7b29-c29e-4d8d-b1d2-e2fbd96a45b5",
   "metadata": {},
   "source": [
    "## 2. Functions for generating python commands, and deploying jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028e682c-2331-4c73-9388-4916ffb7fe11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_python_command(d, m, sz, rep0, repn, rerun, compute_mmd, recompute_mmd, log_folder,\n",
    "                       symm1=1, rh2 = 0,\n",
    "                   alg = \"kt\", compress_alg=None, n_compress=None, g=None,\n",
    "                       setting = \"gauss\", M=None, filename=None,\n",
    "                       results_folder = None, mcmc_folder = None,\n",
    "                       timing_experiment=False, \n",
    "                         ):\n",
    "    '''\n",
    "    return python string deploying an experiment\n",
    "    Args:\n",
    "        d: (int) dimension of the problem\n",
    "        m: (int) thinning factor in log_2 base (useful typically only for kt.thin)\n",
    "        sz: (int) the size of input data in log_4 base \n",
    "        rep0: (int) starting rep id\n",
    "        repn: (int) number of reps\n",
    "        rerun: (int) whether to rerun experiments when set to anything but 0, else 0\n",
    "        compute_mmd: (int) whether to compute mmd when set to anything but 0, else 0\n",
    "        recompute_mmd: (bool) whether to recompute mmd (i.e., ignore pkl file if mmd already exists) when set to anything but 0, else 0\n",
    "        log_folder: (str) folder for saving out/err files (useful only when deplying jobs via terminal, and not for slurm)\n",
    "        symm1: (int) whether to use symmetrize in stage 1 of compress++ when set to anything but 0, else 0\n",
    "        alg: (str) name of the main thinning algorithm\n",
    "        compress_alg: (int) the algorithm to be used for thinning in compress\n",
    "        n_compress: (int) number of compress coresets to be generated\n",
    "        g: (int) the oversampling factor \"g\" for compress++ experiments\n",
    "        setting: (str) target P; take values in gauss/mog/mcmc\n",
    "        M: (int) number of mog components\n",
    "        filename: (str) name of mcmc file\n",
    "        results_folder: (str) location for saving results\n",
    "        mcmc_folder : (str) location from where to load the mcmc data\n",
    "        timing_experiment: (bool) whether this experiment is about computing runtime only\n",
    "    \n",
    "    '''\n",
    "    assert(results_folder is not None)\n",
    "    pathlib.Path(results_folder).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    if not timing_experiment:\n",
    "        exp_name =  ['python3', f'construct_{alg}_coresets.py']\n",
    "    else:\n",
    "        exp_name =  ['python3', f'run_time.py']\n",
    "    \n",
    "    exp_name.extend(['--m', f'{m}', f'--size', f'{sz}', '--setting', f'{setting}', '--rep0', f'{rep0}', \n",
    "                     '--repn', f'{repn}','--rerun', str(rerun), '--computemmd', str(compute_mmd), \n",
    "                     '--recomputemmd', str(recompute_mmd), '--symm1', str(symm1), \n",
    "                     '--resultsfolder', f'{results_folder}'\n",
    "                    ])\n",
    "    \n",
    "    if alg == \"compresspp\":\n",
    "        assert(compress_alg is not None)\n",
    "        exp_name.extend(['--compressalg', f'{compress_alg}']) \n",
    "        assert(g is not None)\n",
    "        exp_name.extend(['--g', f'{g}']) \n",
    "         \n",
    "    if setting == \"mog\":\n",
    "        exp_name.extend(['--M', f'{M}'])\n",
    "    \n",
    "    if setting != \"mcmc\":\n",
    "        exp_name.extend(['--d', f'{d}'])# add dimension for non mcmc settings\n",
    "    else:\n",
    "        exp_name.extend(['--filename', f'{filename}'])\n",
    "        assert(mcmc_folder is not None)\n",
    "        exp_name.extend(['--mcmcfolder', f'{mcmc_folder}'])\n",
    "        \n",
    "       \n",
    "\n",
    "    \n",
    "    log_file = ''.join(exp_name[1:])\n",
    "    # removing redundant characters to save space\n",
    "    log_file = log_file.replace(\"--\", \"-\")\n",
    "    for s in [\"construct_\", \"_coresets\", \".py\"]:\n",
    "        log_file = log_file.replace(s, \"\")\n",
    "    # adding time stamp\n",
    "    suffix = datetime.now().strftime('%H_%M')\n",
    "    out_file = os.path.join(log_folder, log_file+suffix+\".out\")\n",
    "    err_file = os.path.join(log_folder, log_file+suffix+\".err\")\n",
    "    \n",
    "    return(exp_name, out_file, err_file)\n",
    "\n",
    "def deploy_terminal_run(exp_name, out, err):\n",
    "    '''\n",
    "    deploy a python job as a python subprocess on terminal\n",
    "    \n",
    "    Args:\n",
    "        exp_name: (str) command for the job\n",
    "        out: (str) filename to save std_out\n",
    "        err: (str) filename to save std_err\n",
    "    '''\n",
    "    with open(out, \"wb\") as f:\n",
    "        with open(err, \"wb\") as f2:\n",
    "            subprocess.Popen(exp_name, stdout=f, stderr=f2)\n",
    "        return\n",
    "    \n",
    "def deploy_slurm_run(exp_name, partition, prefix):\n",
    "    '''\n",
    "    deploy a python job as a slurm job\n",
    "    \n",
    "    Args:\n",
    "        exp_name: (str) command for the job\n",
    "        partition: (str) partion name on the cluster\n",
    "        prefix: (str) prefix for the slurm job that is displayed in squeue\n",
    "    '''\n",
    "    if partition != \"jsteinhardt\":\n",
    "        s = Slurm(prefix, {\"partition\": partition,\n",
    "                     \"c\": 1\n",
    "                       \n",
    "                    })\n",
    "    else:\n",
    "        \n",
    "        s = Slurm(prefix, {\"partition\": partition,  })\n",
    "    s.run('module load python; ' + \" \".join(exp_name))\n",
    "    return(s)\n",
    "\n",
    "def deploy_experiment(deploy_slurm, ids, exp_name, out, err, partition, prefix, debug=False):\n",
    "    '''\n",
    "    deploy a python experiment via terminal or slurm and append the job id / experiment name to ids\n",
    "    \n",
    "    Args:\n",
    "        deploy_slurm: (Bool) if True deploy a slurm job, else a terminal job\n",
    "        ids: (list) list of deployed experiments\n",
    "        exp_name: (str) command for the job\n",
    "        out: (str) filename to save std_out when deploying a terminal job\n",
    "        err: (str) filename to save std_err when deploying a terminal job\n",
    "        partition: (str) partion name on the cluster when deploying a slurm job\n",
    "        prefix: (str) prefix for the slurm job that is displayed in squeue when deploying a slurm job\n",
    "        debug: (bool) do not deploy when true, else deploy\n",
    "    '''\n",
    "    if debug:\n",
    "        ids.append(\" \".join(exp_name))\n",
    "        return\n",
    "    \n",
    "    if deploy_slurm:\n",
    "        ids.append(deploy_slurm_run(partition=partition, prefix=prefix, exp_name=exp_name))\n",
    "    else:\n",
    "        deploy_terminal_run(exp_name, out, err)\n",
    "        ids.append(exp_name)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2506eac-dfd3-4ac2-aaef-fb606111151a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_exp_setting(ds, total_reps, reps_per_job, alg, target, Ms=None, filenames=None, gs=None, ms=None):\n",
    "    '''\n",
    "    print out experiment setting\n",
    "    \n",
    "    Args:\n",
    "        ds: (list) the dimensionality of experiments\n",
    "        total_reps: (int) the number of reps\n",
    "        reps_per_job: (int) number of reps for each job\n",
    "        alg: (str) the algorithm\n",
    "        target: (str) target P\n",
    "        Ms: (list) range of M for Mog target\n",
    "        filenames: (list) list of mcmc settings\n",
    "        gs: (list) list of oversampling factors for Compress++\n",
    "        ms : (list) sizes (useful for MCMC experiments where these differ file by file)\n",
    "    '''\n",
    "    if filenames is not None:\n",
    "        print(f'Running {alg} experiments, gs={gs}, for {target} target for settings = {filenames} in d = {ds}, '\n",
    "              + f'm = {ms}, total_reps = {total_reps},' +\n",
    "                 f' with {reps_per_job} reps per python call')\n",
    "    elif Ms is not None:\n",
    "        print(f'Running {alg} experiments, gs={gs}, for {target} target for M = {Ms} in d = {ds}, ' \n",
    "                + f'm = {ms}, total_reps = {total_reps},' +\n",
    "                 f' with {reps_per_job} reps per python call')\n",
    "    else:\n",
    "        print(f'Running {alg} experiments, gs={gs}, for {target} target for d = {ds}, ' \n",
    "                + f'm = {ms}, total_reps = {total_reps},' +\n",
    "                 f' with {reps_per_job} reps per python call')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4beff2-a6f0-4422-8625-c0860c0c411f",
   "metadata": {},
   "outputs": [],
   "source": [
    "partitions = [\"high\", \"yugroup\", \"jsteinhardt\", \"low\"]\n",
    "results_folder = \"coresets_folder\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147d41a0-caef-451e-b06e-137d0bdcc061",
   "metadata": {},
   "source": [
    "## 4. Run Gauss Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccbb165-678b-4b78-b723-51b4baca4861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coresets to generate\n",
    "st_coresets = False\n",
    "kt_coresets = False\n",
    "herding_coresets = False\n",
    "\n",
    "cpp_kt_coresets = True\n",
    "cpp_herding_coresets = False\n",
    "\n",
    "### ASSUMING SIZE = 4^m; and final output = sqrt(SIZE) = 2^m #####\n",
    "ms = range(9, 10+1) # range of m\n",
    "gs = [0, 4] # oversampling factors; will ignore Compress++ run for g>m\n",
    "\n",
    "# define repetition\n",
    "total_reps = 10 # set this to the max number of repetitions\n",
    "reps_per_job = 1 # number of reps per python call\n",
    "\n",
    "symm1 = 1 # whether want use symmetrized halving in compress\n",
    "\n",
    "compute_mmd = 1 # whether to compute mmd\n",
    "\n",
    "### whether to regenerate coreset / recompute MMD / IMPORTANT NOTE DIFFERENT FLAGS ####\n",
    "### if we want to recompute mmds (for some reason) then we have to set that flag to True ##\n",
    "rerun = 0 # regenerate coresets?\n",
    "recompute_mmd = 0 # recompute mmd? works ONLY if compute_mmd is true in the first place\n",
    "\n",
    "### All experiments are run with Gauss(sigma) as k and Gauss(sigma/sqrt(2)) as krt ###\n",
    "run_gauss_experiments = True # run experiments with Gauss P\n",
    "ds = [2, 4, 10, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2201b356-9e9e-4c52-a4e4-201d02dfb5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = False # whether to actually deploy experiments (False), or just return a list of python commands to be deployed (True)\n",
    "partition = partitions[2] # \"high\", \"yugroup\", \"jsteinhardt\", \"low\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879401ef-b83b-468d-8882-2b93d67d69a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gauss_ids = []\n",
    "if run_gauss_experiments:\n",
    "    log_folder = f\"logs/{datetime.now().strftime('%b_%d_%Y')}\"\n",
    "    pathlib.Path(log_folder).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    target=\"gauss\"\n",
    "    \n",
    "    # run st/kt/herding experiments\n",
    "    for flag, alg in zip([st_coresets, kt_coresets, herding_coresets], [\"st\", \"kt\", \"herding\"]):\n",
    "        if flag:\n",
    "            print_exp_setting(ds, total_reps, reps_per_job, alg=alg, target=target)\n",
    "            for d in ds:\n",
    "                for m in ms:\n",
    "                    for i in range(0, total_reps, reps_per_job):\n",
    "                        # experiment command, and filenames\n",
    "                        exp_name, out, err = get_python_command(d=d, m=m, sz=m, rep0=i, repn=reps_per_job, \n",
    "                                                  rerun=rerun, compute_mmd=compute_mmd, \n",
    "                                                  recompute_mmd=recompute_mmd, log_folder=log_folder,\n",
    "                                                  alg=alg, compress_alg=None, n_compress=None, g=None,\n",
    "                                                  setting=target, symm1=symm1, results_folder=results_folder)\n",
    "                        prefix = alg[:1] + target[:1] + f\"d{d}n{m}r{i}\"\n",
    "                        deploy_experiment(deploy_slurm, gauss_ids, exp_name, out, err, partition, prefix=prefix, debug=debug)\n",
    "\n",
    "    # compress++ experiments\n",
    "    for flag, compress_alg in zip([cpp_kt_coresets, cpp_herding_coresets], [\"kt\", \"herding\"]):\n",
    "        if flag:\n",
    "            alg = \"compresspp\"\n",
    "            print_exp_setting(ds, total_reps, reps_per_job, alg=alg+f\"({compress_alg})\", target=target, gs=gs, ms=ms)\n",
    "            for d in ds:\n",
    "                for m in ms:\n",
    "                    for g in gs:\n",
    "                        if g > m:\n",
    "                            continue # skip the loop\n",
    "                        for i in range(0, total_reps, reps_per_job):\n",
    "                            # experiment command, and filenames\n",
    "                            exp_name, out, err = get_python_command(d=d, m=m, sz=m, rep0=i, repn=reps_per_job, \n",
    "                                                  rerun=rerun, compute_mmd=compute_mmd, \n",
    "                                                  recompute_mmd=recompute_mmd, log_folder=log_folder,\n",
    "                                                  alg=alg, compress_alg=compress_alg,  n_compress=None, g=g,\n",
    "                                                setting=target, symm1=symm1, results_folder=results_folder)\n",
    "                            prefix = alg[:1] + str(g) + compress_alg[:1] + target[:1] + f\"d{d}n{m}r{i}\"\n",
    "                            deploy_experiment(deploy_slurm, gauss_ids, exp_name, out, err, partition, prefix=prefix, debug=debug)\n",
    "                                            \n",
    "                            \n",
    "    print(f'{partition} partition; Number of processes/jobs:{len(gauss_ids)} slurm:{deploy_slurm}, terminal: {not deploy_slurm}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8bb2d6-eba2-45b3-8e13-eb4897ff7a97",
   "metadata": {},
   "source": [
    "## 5. Run MOG experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c992f69c-1263-4377-89cc-2f1dfe17aa58",
   "metadata": {},
   "outputs": [],
   "source": [
    "### All experiments are run with Gauss(sigma) as k and Gauss(sigma/sqrt(2)) as krt ###\n",
    "run_mog_experiments = True # run experiments with MoG P\n",
    "Ms = [4, 6, 8] # supports, 3, 4, 6, 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9a0b4b-7501-4fec-93df-cbab26171040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coresets to generate\n",
    "st_coresets = False\n",
    "kt_coresets = False\n",
    "herding_coresets = False\n",
    "\n",
    "cpp_kt_coresets = True\n",
    "cpp_herding_coresets = False\n",
    "\n",
    "### ASSUMING SIZE = 4^m; and final output = sqrt(SIZE) = 2^m #####\n",
    "ms = range(9, 10+1) # range of m\n",
    "gs = [0, 4] # oversampling factors; will ignore Compress++ run for g>m\n",
    "\n",
    "# define repetition\n",
    "total_reps = 10 # set this to the max number of repetitions\n",
    "reps_per_job = 1 # number of reps per python call\n",
    "\n",
    "symm1 = 1 # whether want use symmetrized halving in compress\n",
    "\n",
    "compute_mmd = 1 # whether to compute mmd\n",
    "\n",
    "### whether to regenerate coreset / recompute MMD / IMPORTANT NOTE DIFFERENT FLAGS ####\n",
    "### if we want to recompute mmds (for some reason) then we have to set that flag to True ##\n",
    "rerun = 0 # regenerate coresets?\n",
    "recompute_mmd = 0 # recompute mmd? works ONLY if compute_mmd is true in the first place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace5375d-ebcb-499c-bab5-d5e7b612aed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = False\n",
    "partition = partitions[1]  # \"high\", \"yugroup\", \"jsteinhardt\", \"low\"\n",
    "mog_ids = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b77031-9c5e-4015-96c1-7a443f3c8f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_mog_experiments:\n",
    "    log_folder = f\"logs/{datetime.now().strftime('%b_%d_%Y')}\"\n",
    "    pathlib.Path(log_folder).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    d = 2\n",
    "    target=\"mog\"\n",
    "    \n",
    "    # run st/kt/herding experiments\n",
    "    for flag, alg in zip([st_coresets, kt_coresets, herding_coresets], [\"st\", \"kt\", \"herding\"]):\n",
    "        if flag:\n",
    "            print_exp_setting(d, total_reps, reps_per_job, alg=alg, target=target, Ms=Ms, ms=ms)\n",
    "            for M in Ms:\n",
    "                for m in ms:\n",
    "                    for i in range(0, total_reps, reps_per_job):\n",
    "                        # experiment command, and filenames\n",
    "                        exp_name, out, err = get_python_command(d=d, m=m, sz=m, rep0=i, repn=reps_per_job, \n",
    "                                                  rerun=rerun, compute_mmd=compute_mmd, \n",
    "                                                  recompute_mmd=recompute_mmd, log_folder=log_folder,\n",
    "                                                  alg=alg, compress_alg=None, n_compress=None, g=None,\n",
    "                                                setting=target, M=M, symm1=symm1, results_folder=results_folder)\n",
    "                        prefix = alg[:1] + target[1] + f\"M{M}n{m}r{i}\" \n",
    "                        deploy_experiment(deploy_slurm, mog_ids, exp_name, out, err, partition, prefix=prefix, debug=debug)\n",
    "\n",
    "\n",
    "\n",
    "    # compress++ experiments\n",
    "    for flag, compress_alg in zip([cpp_kt_coresets, cpp_herding_coresets], [\"kt\", \"herding\"]):\n",
    "        if flag:\n",
    "            alg = \"compresspp\"\n",
    "            print_exp_setting(d, total_reps, reps_per_job, alg=alg+f\"({compress_alg})\", \n",
    "                              target=target, Ms=Ms, gs=gs, ms=ms)\n",
    "            for M in Ms:\n",
    "                for m in ms:\n",
    "                    for g in gs:\n",
    "                        if g > m:\n",
    "                            continue # skip the loop\n",
    "                        for i in range(0, total_reps, reps_per_job):\n",
    "                            # experiment command, and filenames\n",
    "                            exp_name, out, err = get_python_command(d=d, m=m, sz=m, rep0=i, repn=reps_per_job, \n",
    "                                                  rerun=rerun, compute_mmd=compute_mmd, \n",
    "                                                  recompute_mmd=recompute_mmd, log_folder=log_folder,\n",
    "                                                  alg=alg, compress_alg=compress_alg,  n_compress=None, \n",
    "                                                  g=g, setting=target, M=M, symm1=symm1, results_folder=results_folder)\n",
    "                            prefix = alg[:1] + str(g) + compress_alg[:1] +  target[1] + f\"M{M}n{m}r{i}\" \n",
    "                            deploy_experiment(deploy_slurm, mog_ids, exp_name, out, err, partition, prefix=prefix, debug=debug)\n",
    "                                \n",
    "                        \n",
    "    print(f'{partition} partition; Number of processes/jobs:{len(mog_ids)} slurm:{deploy_slurm}, terminal: {not deploy_slurm}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093ab5c2-5490-4915-9ba4-086f2c01108b",
   "metadata": {},
   "source": [
    "## 6. Run MCMC experiments (we set parameters again)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08f3a74-452d-4515-a488-220eddb470bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coresets to generate\n",
    "st_coresets = False\n",
    "kt_coresets = True\n",
    "herding_coresets = False\n",
    "\n",
    "cpp_kt_coresets = False\n",
    "cpp_herding_coresets = False\n",
    "\n",
    "### ASSUMING SIZE = 4^m; and final output = sqrt(SIZE) = 2^m #####\n",
    "ms = range(4, 8+1) # range of m\n",
    "gs = [0, 4] # oversampling factors; will ignore Compress++ run for g>m\n",
    "\n",
    "# define repetition\n",
    "total_reps = 10 # set this to the max number of repetitions\n",
    "reps_per_job = 1 # number of reps per python call\n",
    "\n",
    "symm1 = 1 # whether want use symmetrized halving in compress\n",
    "\n",
    "compute_mmd = 1 # whether to compute mmd\n",
    "\n",
    "### whether to regenerate coreset / recompute MMD / IMPORTANT NOTE DIFFERENT FLAGS ####\n",
    "### if we want to recompute mmds (for some reason) then we have to set that flag to True ##\n",
    "rerun = 0 # regenerate coresets?\n",
    "recompute_mmd = 0 # recompute mmd? works ONLY if compute_mmd is true in the first place\n",
    "\n",
    "run_mcmc_experiments = True # run experiments with MCMC P\n",
    "all_mcmc_filenames = ['Goodwin_RW', 'Goodwin_ADA-RW', \n",
    "'Goodwin_MALA', 'Goodwin_PRECOND-MALA', \n",
    "'Lotka_RW', 'Lotka_ADA-RW', \n",
    "'Lotka_MALA', 'Lotka_PRECOND-MALA',  \n",
    "     'Hinch_P_seed_1_temp_1_scaled_nosplit',\n",
    "     'Hinch_P_seed_2_temp_1_scaled_nosplit',\n",
    "     'Hinch_TP_seed_1_temp_8_scaled_nosplit', \n",
    "     'Hinch_TP_seed_2_temp_8_scaled_nosplit']\n",
    "\n",
    "run_mcmc_experiments = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5717340-8b2e-4e6d-8c8a-4885e4c5dd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcmc_folder = \"/accounts/projects/binyu/raaz.rsk/kernel_thinning/kernel_thinning_plus/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a46d917-85d1-4a5d-bf81-b9e12fd709de",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcmc_file_range = slice(0, 12)\n",
    "mcmc_filenames = all_mcmc_filenames[mcmc_file_range]\n",
    "print(mcmc_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0960f4f-60c5-4402-9755-76640e04fd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ASSUMING SIZE = 4^m; and final output = sqrt(SIZE) = 2^m #####\n",
    "# the range of allowed ms is 4^4 to 4^8 for all Hinch experiments and Lotka_ADA-RW;\n",
    "# the range of allowed ms is 4^4 to 4^9 for all other experiments;\n",
    "\n",
    "min_m = 4 # to cap the min size of experiments regardless of allowed ms;\n",
    "max_m = 8 # to cap the max size of experiments regardless of allowed ms;\n",
    "# the range is truncted to min(max_allowed_range, max_m)\n",
    "\n",
    "ms_ranges = dict()\n",
    "for filename in all_mcmc_filenames:\n",
    "    if ('Hinch' in filename) or (filename == 'Lotka_ADA-RW'):\n",
    "        ms_ranges[filename] = range(max(4, min_m), min(8, max_m)+1)\n",
    "    else:\n",
    "        ms_ranges[filename] = range(max(4, min_m), min(9, max_m)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9938d466-4051-4735-9044-4dd17219cafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = False\n",
    "partition = partitions[2] # \"high\", \"yugroup\", \"jsteinhardt\", \"low\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de2f867-02a9-4134-b7ee-6972b7104893",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcmc_ids = []\n",
    "if run_mcmc_experiments:\n",
    "    log_folder = f\"logs/{datetime.now().strftime('%b_%d_%Y')}\"\n",
    "    pathlib.Path(log_folder).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    d = 0 # None # no fixed d\n",
    "    target=\"mcmc\"\n",
    "    \n",
    "    # run st/kt/herding experiments\n",
    "    for flag, alg in zip([st_coresets, kt_coresets, herding_coresets], [\"st\", \"kt\", \"herding\"]):\n",
    "        if flag:\n",
    "            print_exp_setting(d, total_reps, reps_per_job, alg=alg, target=target, Ms=None, filenames=mcmc_filenames, ms=ms_ranges)\n",
    "            for filename in mcmc_filenames:\n",
    "                for m in ms_ranges[filename]:\n",
    "                    for i in range(0, total_reps, reps_per_job):\n",
    "                        # experiment command, and filenames\n",
    "                        exp_name, out, err = get_python_command(d=d, m=m, sz=m, rep0=i, repn=reps_per_job, \n",
    "                                                  rerun=rerun, compute_mmd=compute_mmd, \n",
    "                                                  recompute_mmd=recompute_mmd, log_folder=log_folder,\n",
    "                                                  alg=alg, compress_alg=None, n_compress=None, g=None,\n",
    "                                                setting=target, filename=filename, symm1=symm1, results_folder=results_folder, mcmc_folder = mcmc_folder)\n",
    "                        prefix = alg[:1] + filename[:2] + f\"d{d}n{m}r{i}\" \n",
    "                        deploy_experiment(deploy_slurm, mcmc_ids, exp_name, out, err, partition, prefix=prefix, debug=debug)\n",
    "                        \n",
    "    # compress++ experiments\n",
    "    for flag, compress_alg in zip([cpp_kt_coresets, cpp_herding_coresets], [\"kt\", \"herding\"]):\n",
    "        if flag:\n",
    "            alg = \"compresspp\"\n",
    "            print_exp_setting(d, total_reps, reps_per_job, alg=alg+f\"({compress_alg})\", \n",
    "                              target=target, Ms=None,filenames=mcmc_filenames, gs=gs, ms=ms_ranges)\n",
    "            for filename in mcmc_filenames:\n",
    "                for m in ms_ranges[filename]:\n",
    "                    for g in gs:\n",
    "                        if g > m:\n",
    "                            continue\n",
    "                        for i in range(0, total_reps, reps_per_job):\n",
    "                            # experiment command, and filenames\n",
    "                            exp_name, out, err = get_python_command(d=d, m=m, sz=m, rep0=i, repn=reps_per_job, \n",
    "                                                  rerun=rerun, compute_mmd=compute_mmd, \n",
    "                                                  recompute_mmd=recompute_mmd, log_folder=log_folder,\n",
    "                                                  alg=alg, compress_alg=compress_alg,  n_compress=None, \n",
    "                                                  g=g, setting=target, filename=filename, symm1=symm1, results_folder=results_folder, mcmc_folder = mcmc_folder)\n",
    "                            prefix = alg[:1] + compress_alg[:1]  + filename[:1] + filename[5:6] + f\"n{m}r{i}\" \n",
    "                            deploy_experiment(deploy_slurm, mcmc_ids, exp_name, out, err, partition, prefix=prefix, debug=debug)\n",
    "                                \n",
    "    print(f'{partition} partition; Number of processes/jobs:{len(mcmc_ids)} slurm:{deploy_slurm}, terminal: {not deploy_slurm}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f764a3-e592-4c7c-940b-0d17d37ca536",
   "metadata": {},
   "source": [
    "## 7. Runtime experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4194f2fc-86de-4edc-8cfe-3ce025767313",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_folder = \"results/run_time\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad969bd0-8a4c-4de1-a972-d4b72360fb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coresets to generate\n",
    "\n",
    "st_coresets = False\n",
    "kt_coresets = True\n",
    "herding_coresets = False\n",
    "\n",
    "cpp_kt_coresets = False\n",
    "cpp_herding_coresets = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7e1a63-781e-457e-82e5-805f6140c37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ASSUMING SIZE = 4^m; and final output = sqrt(SIZE) = 2^m #####\n",
    "ms = range(4, 5+1) # range of m\n",
    "gs = [0, 4] # oversampling factors; will ignore C++ run for g>m\n",
    "\n",
    "# define repetition\n",
    "total_reps = 3 # set this to the max number of repetitions\n",
    "reps_per_job = 1 # number of reps per python call\n",
    "\n",
    "symm1 = 1 # whether want use symetric compress in stage 1;\n",
    "\n",
    "rerun = 0 # re generate coresets\n",
    "\n",
    "### All experiments are run with Gauss(sigma) as k and Gauss(sigma/sqrt(2)) as krt ###\n",
    "runtime_gauss_experiments = True # run experiments with Gauss P\n",
    "ds = [2] #, 4, 10, 100]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457a200f-bc7c-4a3e-b103-177133aeef75",
   "metadata": {},
   "outputs": [],
   "source": [
    "gauss_ids = []\n",
    "if runtime_gauss_experiments:\n",
    "    log_folder = f\"logs/{datetime.now().strftime('%b_%d_%Y')}\"\n",
    "    pathlib.Path(log_folder).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    target=\"gauss\"\n",
    "    \n",
    "    # run st/kt/herding experiments\n",
    "    for flag, alg in zip([st_coresets, kt_coresets, herding_coresets], [\"st\", \"kt\", \"herding\"]):\n",
    "        if flag:\n",
    "            print_exp_setting(ds, total_reps, reps_per_job, alg=alg, target=target)\n",
    "            for d in ds:\n",
    "                for m in ms:\n",
    "                    for i in range(0, total_reps, reps_per_job):\n",
    "                        # experiment command, and filenames\n",
    "                        exp_name, out, err = get_python_command(d=d, m=m, sz=m, rep0=i, repn=reps_per_job, \n",
    "                                                  rerun=rerun, compute_mmd=compute_mmd, \n",
    "                                                  recompute_mmd=recompute_mmd, log_folder=log_folder,\n",
    "                                                  alg=alg, compress_alg=None, n_compress=None, g=None,\n",
    "                                                  setting=target,\n",
    "                                                symm1=symm1, timing_experiment=True, results_folder = results_folder)\n",
    "                        prefix = 'rt' + alg[:1] + target[:1] + f\"d{d}n{m}r{i}\"\n",
    "                        deploy_experiment(deploy_slurm, gauss_ids, exp_name, out, err, partition, prefix=prefix, debug=debug)\n",
    "\n",
    "    # compress++ experiments\n",
    "    for flag, compress_alg in zip([cpp_kt_coresets, cpp_herding_coresets], [\"kt\", \"herding\"]):\n",
    "        if flag:\n",
    "            alg = \"compresspp\"\n",
    "            print_exp_setting(ds, total_reps, reps_per_job, alg=alg+f\"({compress_alg})\", target=target, gs=gs)\n",
    "            for d in ds:\n",
    "                for m in ms:\n",
    "                    for g in gs:\n",
    "                        if g > m:\n",
    "                            continue # skip the loop\n",
    "                        for i in range(0, total_reps, reps_per_job):\n",
    "                            # experiment command, and filenames\n",
    "                            exp_name, out, err = get_python_command(d=d, m=m, sz=m, rep0=i, repn=reps_per_job, \n",
    "                                                  rerun=rerun, compute_mmd=compute_mmd, \n",
    "                                                  recompute_mmd=recompute_mmd, log_folder=log_folder,\n",
    "                                                  alg=alg, compress_alg=compress_alg,  n_compress=None, g=g,\n",
    "                                                setting=target,\n",
    "                                                symm1=symm1, timing_experiment=True, results_folder = results_folder)\n",
    "                            prefix = 'rt' + alg[:1] + str(g) + compress_alg[:1] + target[:1] + f\"d{d}n{m}r{i}\"\n",
    "                            deploy_experiment(deploy_slurm, gauss_ids, exp_name, out, err, partition, prefix=prefix, debug=debug)\n",
    "                                            \n",
    "                            \n",
    "    print(f'{partition} partition; Number of processes/jobs:{len(gauss_ids)} slurm:{deploy_slurm}, terminal: {not deploy_slurm}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e8621a-d441-446b-a268-11ec3f4bbc46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
